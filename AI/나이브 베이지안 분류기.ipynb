{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1502c386",
   "metadata": {},
   "source": [
    "# Chapter 11 나이브 베이지안 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cfbd2f",
   "metadata": {},
   "source": [
    "## 02 베이즈 분류기 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a7f00",
   "metadata": {},
   "source": [
    "'viagra' 단어가 들어가 있을 때 해당 메일이 스팸 메일일 확률 P(spam|viagra)\n",
    "\n",
    "P(viagra) = 6/20\n",
    "\n",
    "P(spam) = 6/20\n",
    "\n",
    "P(viagra|spam) = 3/6\n",
    "\n",
    "=> viagra라는 글자가 존재할 때 해당 메일이 스팸일 확률 P(spam|viagra) = 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "520ce172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "viagra_spam={'viagra':[1,0,0,0,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,1],\n",
    "            'spam':[1,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,1,1,1]}\n",
    "df=pd.DataFrame(viagra_spam,columns=['viagra','spam'])\n",
    "np_data=df.values\n",
    "np_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1028a10d",
   "metadata": {},
   "source": [
    "viagra 단어를 포함하면서 스팸메일인 경우의 확률: P(viagra∩spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33fc520c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((np_data[:,0]==1) & (np_data[:,1]==1))/20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeefd75",
   "metadata": {},
   "source": [
    "P(viagra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32c5456f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_viagra=sum(np_data[:,0]==1)/len(np_data)\n",
    "p_viagra # P(viagra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206d35df",
   "metadata": {},
   "source": [
    "P(spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f20a43f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_spam=sum(np_data[:,1]==1)/len(np_data)\n",
    "p_spam # P(spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa6f368",
   "metadata": {},
   "source": [
    "P(viagra∩spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d5a8d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_v_cap_s=sum((np_data[:,0]==1) & (np_data[:,1]==1))/len(np_data)\n",
    "p_v_cap_s # P(viagra∩spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2227d0",
   "metadata": {},
   "source": [
    "P(~viagra∩spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "453c7edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_n_v_cap_s=sum((np_data[:,0]==0) & (np_data[:,1]==1))/len(np_data)\n",
    "p_n_v_cap_s # P(~viagra∩spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44547d6",
   "metadata": {},
   "source": [
    "viagra 라는 단어가 들어갔을 때 스팸메일일 확률: P(spam|viagra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e1191cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_spam * (p_v_cap_s/p_spam)/p_viagra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad96828",
   "metadata": {},
   "source": [
    "viagra 라는 단어가 들어가지 않았을 때 스팸메일일 확률: P(spam|~viagra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41976dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2142857142857143"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_spam * (p_v_cap_s/p_spam)/(1-p_viagra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b335fc",
   "metadata": {},
   "source": [
    "viagra 라는 단어가 포함되었을 때 스팸메일일 확률(=0.5)은\n",
    "\n",
    "viagra 라는 단어가 포함되지 않았을 때 스팸메일일 확률(=0.2142857142857143)보다 높다.\n",
    "\n",
    "=> 이 결과로만 봤을 때, viagra라는 단어가 있으면 스팸메일로 분류하는 것이 좀 더 합리적인 선택이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d352a4d1",
   "metadata": {},
   "source": [
    "## 03 나이브 베이지안 분류기 구현하기\n",
    "#### 베이즈 분류기가 하나의 변수만을 고려하는 것에 반해 나이브 베이지안 분류기는 여러 개의 열을 사용하여 분류기를 구성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c55d52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>History</th>\n",
       "      <th>CoApplicant</th>\n",
       "      <th>Accommodation</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>paid</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>paid</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>paid</td>\n",
       "      <td>guarantor</td>\n",
       "      <td>rent</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>arrears</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  History CoApplicant Accommodation  Fraud\n",
       "0   1  current        none           own   True\n",
       "1   2     paid        none           own  False\n",
       "2   3     paid        none           own  False\n",
       "3   4     paid   guarantor          rent   True\n",
       "4   5  arrears        none           own  False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_url=\"c:/Users/user/ch11/fraud.csv\"\n",
    "df=pd.read_csv(data_url,sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf1394da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>History_arrears</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>History_current</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>History_none</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>History_paid</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoApplicant_coapplicant</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoApplicant_guarantor</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoApplicant_none</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accommodation_free</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accommodation_own</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accommodation_rent</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0  1  2  3  4  5  6  7  8  9\n",
       "History_arrears          0  0  0  0  1  1  0  1  0  0\n",
       "History_current          1  0  0  0  0  0  1  0  1  0\n",
       "History_none             0  0  0  0  0  0  0  0  0  1\n",
       "History_paid             0  1  1  1  0  0  0  0  0  0\n",
       "CoApplicant_coapplicant  0  0  0  0  0  0  0  0  0  0\n",
       "CoApplicant_guarantor    0  0  0  1  0  0  0  0  0  0\n",
       "CoApplicant_none         1  1  1  0  1  1  1  1  1  1\n",
       "Accommodation_free       0  0  0  0  0  0  0  0  0  0\n",
       "Accommodation_own        1  1  1  0  1  1  1  1  0  1\n",
       "Accommodation_rent       0  0  0  1  0  0  0  0  1  0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df[\"ID\"] # ID열 삭제\n",
    "Y_data = df.pop(\"Fraud\") # Fraud열 pop으로 원본에서 삭제시키고 Y_data에 Fraud열 저장\n",
    "Y_data = Y_data.values\n",
    "x_df = pd.get_dummies(df) # 원핫인코딩\n",
    "x_df.head(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a43ae20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = x_df.values # x_df의 값을 넘파이 배열 형태로 저장\n",
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f7006e",
   "metadata": {},
   "source": [
    "나이브 베이지안 수식을 코드로 표현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "029655bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3, 0.7)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_Y_True = sum(Y_data==True) / len(Y_data)\n",
    "P_Y_False = 1 - P_Y_True\n",
    "\n",
    "P_Y_True,P_Y_False # Y값이 True인 경우와 False인 경우의 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b3a167",
   "metadata": {},
   "source": [
    "- np.where 함수: 특정 조건을 만족하는 값의 인덱스를 반환하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d236b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  3,  5,  9, 11, 12], dtype=int64),)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(Y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f2588b",
   "metadata": {},
   "source": [
    "y_data=True,False인 각각의 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2584944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 0,  3,  5,  9, 11, 12], dtype=int64),),\n",
       " (array([ 1,  2,  4,  6,  7,  8, 10, 13, 14, 15, 16, 17, 18, 19],\n",
       "        dtype=int64),))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_Y_True = np.where(Y_data)\n",
    "ix_Y_False = np.where(Y_data==False)\n",
    "\n",
    "ix_Y_True, ix_Y_False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52ae5315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.16666667, 0.5       , 0.16666667, 0.16666667, 0.        ,\n",
       "        0.16666667, 0.83333333, 0.        , 0.66666667, 0.33333333]),\n",
       " array([0.42857143, 0.28571429, 0.        , 0.28571429, 0.14285714,\n",
       "        0.        , 0.85714286, 0.07142857, 0.78571429, 0.14285714]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_x_y_true = (x_data[ix_Y_True].sum(axis=0)) / sum(Y_data==True) # y_data=True인 인덱스에 존재하는 x_data의 합을 y_data=True인 개수(6개)로 나눠주기\n",
    "p_x_y_false = (x_data[ix_Y_False].sum(axis=0)) / sum(Y_data==False) # y_data=False인 인덱스에 존재하는 x_data의 합을 y_data=False인 개수(14개)로 나눠주기\n",
    "\n",
    "p_x_y_true, p_x_y_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bacd2d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.6333333333333333, 1.7714285714285714)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = [0,1,0,0,0,1,0, 0,1,0]\n",
    "\n",
    "p_y_true_test = P_Y_True + p_x_y_true.dot(x_test)\n",
    "p_y_false_test = P_Y_False + p_x_y_false.dot(x_test)\n",
    "\n",
    "p_y_true_test , p_y_false_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e4c6cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_y_true_test < p_y_false_test # false_test가 더 크다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab3d61c",
   "metadata": {},
   "source": [
    "#### 하나의 문장이 있을 때 이 문장을 sports와 not sports로 나누는 분류기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1df210d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "y_example_text = [\"Sports\", \"Not sports\",\"Sports\",\"Sports\",\"Not sports\"]\n",
    "y_example = [1 if c==\"Sports\" else 0 for c in y_example_text ] # sports가 y_example_text에 있으면 1 없으면 0\n",
    "print(y_example)\n",
    "text_example = [\"A great game game\", \"The The election was over\",\n",
    "                \"Very clean game match\",\n",
    "                \"A clean but forgettable game game\",\n",
    "                \"It was a close election\", ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b794ac2",
   "metadata": {},
   "source": [
    "- BoW(Bag of Words): 단어별로 인덱스가 부여되어 있을 때 한 문장 또는 한 문서에 대한 벡터를 표현하는 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ab50c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['but',\n",
       " 'clean',\n",
       " 'close',\n",
       " 'election',\n",
       " 'forgettable',\n",
       " 'game',\n",
       " 'great',\n",
       " 'it',\n",
       " 'match',\n",
       " 'over',\n",
       " 'the',\n",
       " 'very',\n",
       " 'was']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "countvect_example = CountVectorizer() # BoW 벡터를 생성하기 위한 클래스\n",
    "X_example = countvect_example.fit_transform(text_example)\n",
    "countvect_example.get_feature_names() # 처리해야 하는 단어들의 모음을 보여줌 = text_example 객체에 존재하는 단어들의 모음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "662270c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
       "       [1, 1, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvect_example.transform(text_example).toarray() # 5개 문장에 대한 각 단어들의 출현한 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4f36b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'great': 6,\n",
       " 'game': 5,\n",
       " 'the': 10,\n",
       " 'election': 3,\n",
       " 'was': 12,\n",
       " 'over': 9,\n",
       " 'very': 11,\n",
       " 'clean': 1,\n",
       " 'match': 8,\n",
       " 'but': 0,\n",
       " 'forgettable': 4,\n",
       " 'it': 7,\n",
       " 'close': 2}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvect_example.vocabulary_ # 각 단어들의 인덱스 번호 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea66dbc",
   "metadata": {},
   "source": [
    "#### 베르누이 나이브 베이지안 분류기\n",
    "- 다루고자 하는 모든 데이터가 불린 피쳐\n",
    "- 사용되는 데이터 타입은 이산형 데이터인데, 이러한 데이터를 모두 불린 타입으로 변경하여 학습\n",
    "    - 정수 타입 숫자라면 임계값 기준으로 True 또는 Fasle로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b4b051b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1, binarize=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf = BernoulliNB(alpha=1, binarize=0) # 모델 만들기\n",
    "clf.fit(X_example, y_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98ce3584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.91629073, -0.51082562])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.class_log_prior_ # 각 클래스마다 prior의 값에 log를 붙여서 값을 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a355788",
   "metadata": {},
   "source": [
    "#### 다항 나이브 베이지안 분류기\n",
    "- 베르누이 분류기와 달리 각 피쳐들이 이산형이지만, 이진값이 아닌 여러 개의 값을 가질 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "979bc9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(X_example, y_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09b83cb",
   "metadata": {},
   "source": [
    "#### 가우시안 나이브 베이지안 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e7af507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_example.toarray(), y_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddecbdc3",
   "metadata": {},
   "source": [
    "## 04 20newsgroup으로 분류 연습하기\n",
    "#### 20newsgroup 데이터셋을 사용하여 나이브 베이지안 분류기로 20개의 뉴스 텍스트 데이터 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a44c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4849b170",
   "metadata": {},
   "source": [
    "##### 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7eb9f98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "news=fetch_20newsgroups(subset='all')\n",
    "news.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6a542b",
   "metadata": {},
   "source": [
    "- data:실제 데이터\n",
    "- filenames: 다운로드된 데이터의 파일 위치\n",
    "- target_names: 데이터 y값의 이름\n",
    "- target: 데이터 y 값의 인덱스\n",
    "- DESCR: 데이터에 대한 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38ad6f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\n",
      "Subject: Pens fans reactions\n",
      "Organization: Post Office, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 12\n",
      "NNTP-Posting-Host: po4.andrew.cmu.edu\n",
      "\n",
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(news.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10224731",
   "metadata": {},
   "source": [
    "y값에 해당하는 target과 target_names 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2dd62303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  3, 17, ...,  3,  1,  7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.target # 데이터 y값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad376199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.target_names # 데이터 y값의 인덱스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1949416",
   "metadata": {},
   "source": [
    "##### 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326a2fe6",
   "metadata": {},
   "source": [
    "데이터 프레임 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43a4810c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: Mamatha Devineni Ratnam &lt;mr47+@andrew.cm...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: mblawson@midway.ecn.uoknor.edu (Matthew ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: hilmi-er@dsv.su.se (Hilmi Eren)\\nSubject...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: guyd@austin.ibm.com (Guy Dawson)\\nSubjec...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: Alexander Samuel McDiarmid &lt;am2o+@andrew...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                News  Target\n",
       "0  From: Mamatha Devineni Ratnam <mr47+@andrew.cm...      10\n",
       "1  From: mblawson@midway.ecn.uoknor.edu (Matthew ...       3\n",
       "2  From: hilmi-er@dsv.su.se (Hilmi Eren)\\nSubject...      17\n",
       "3  From: guyd@austin.ibm.com (Guy Dawson)\\nSubjec...       3\n",
       "4  From: Alexander Samuel McDiarmid <am2o+@andrew...       4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df=pd.DataFrame({'News':news.data,'Target':news.target}) # 데이터프레임 만들기\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0583e66d",
   "metadata": {},
   "source": [
    "Target의 정보를 실제 분류의 이름으로 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87978d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dict={idx:name for idx, name in enumerate(news.target_names)}\n",
    "news_df['Target']=news_df['Target'].replace(target_dict) # Target열 값을 target_dict로 바꾸기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a52701",
   "metadata": {},
   "source": [
    "News열 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb2ddbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From Mamatha Devineni Ratnam Subject Pens fans...</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From Matthew B Lawson Subject Which high perfo...</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From hilmi Hilmi Eren Subject Re ARMENIA SAYS ...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From Guy Dawson Subject Re IDE vs SCSI DMA and...</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From Alexander Samuel McDiarmid Subject driver...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                News                    Target\n",
       "0  From Mamatha Devineni Ratnam Subject Pens fans...          rec.sport.hockey\n",
       "1  From Matthew B Lawson Subject Which high perfo...  comp.sys.ibm.pc.hardware\n",
       "2  From hilmi Hilmi Eren Subject Re ARMENIA SAYS ...     talk.politics.mideast\n",
       "3  From Guy Dawson Subject Re IDE vs SCSI DMA and...  comp.sys.ibm.pc.hardware\n",
       "4  From Alexander Samuel McDiarmid Subject driver...     comp.sys.mac.hardware"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_cleansing(df):\n",
    "    delete_email = re.sub(r'\\b[\\w\\+]+@[\\w]+.[\\w]+.[\\w]+.[\\w]+\\b', ' ', df) # 이메일 제거\n",
    "    delete_number = re.sub(r'\\b|\\d+|\\b', ' ',delete_email) # 불필요 숫자 제거\n",
    "    delete_non_word = re.sub(r'\\b[\\W]+\\b', ' ', delete_number) # 문자 아닌 특수문자 제거\n",
    "    cleaning_result = ' '.join(delete_non_word.split()) # 단어 사이 공백 제거:띄어쓰기별로 분할하고 결합\n",
    "    return cleaning_result\n",
    "\n",
    "news_df.loc[:,'News']=news_df['News'].apply(data_cleansing) # News열에 전처리된 텍스트 적용\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14eaaba",
   "metadata": {},
   "source": [
    "##### 벡터화 하기\n",
    "토큰(token): 인덱스를 지정해야 하는 단어들의 리스트를 정리하는 기법\n",
    "- 어간추출(stemming): 띄어쓰기 기준이 아닌 의미나 역할이 다른 단어들을 기준으로 분리하는 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59507be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "Collecting click\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.7.9-cp39-cp39-win_amd64.whl (262 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Installing collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.1.3 nltk-3.7 regex-2022.7.9 tqdm-4.64.0\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c108599e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['look', 'look', 'look']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import stem\n",
    "stmmer=stem.SnowballStemmer('english')\n",
    "sentence='looking looks looked'\n",
    "[stmmer.stem(word) for word in sentence.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02741179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('imag', 'imag', 'imagin')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stmmer.stem('images'),stmmer.stem('imaging'),stmmer.stem('imagination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ddd7983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "\n",
    "enlish_stemmer = nltk.stem.SnowballStemmer(\"english\")\n",
    "class StemmedCountVectorizer(CountVectorizer): # class 1\n",
    "    def build_analyzer(self): # 함수 재정의\n",
    "        analyzer = super(StemmedCountVectorizer,self).build_analyzer()\n",
    "        return lambda doc: (enlish_stemmer.stem(w) for w in analyzer(doc))\n",
    "    \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "enlish_stemmer = nltk.stem.SnowballStemmer(\"english\")\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer): # class 2\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedTfidfVectorizer,self).build_analyzer()\n",
    "        return lambda doc: (enlish_stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2393e94",
   "metadata": {},
   "source": [
    "##### 모델링하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc26bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB,GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "vectorizer = [CountVectorizer(), TfidfVectorizer(), StemmedCountVectorizer(), StemmedTfidfVectorizer()]\n",
    "# algorithms = [BernoulliNB(), MultinomialNB(), GaussianNB(), LogisticRegression()]\n",
    "algorithms = [MultinomialNB(), LogisticRegression()]\n",
    "\n",
    "pipelines = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8e250da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "for case in list(itertools.product(vectorizer,algorithms)):\n",
    "    pipelines.append(make_pipeline(*case))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b553876",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_params = [(1,1),(1,3)]\n",
    "stopword_params = [\"english\"]\n",
    "lowercase_params = [True, False]\n",
    "max_df_params = np.linspace(0.4, 0.6, num=6) # 0.4에서 0.6까지 6개로 나눔\n",
    "min_df_params = np.linspace(0.0, 0.0, num=1)\n",
    "\n",
    "attributes = {\"ngram_range\":ngrams_params, \"max_df\":max_df_params,\"min_df\":min_df_params,\n",
    "              \"lowercase\":lowercase_params,\"stop_words\":stopword_params}\n",
    "vectorizer_names = [\"countvectorizer\",\"tfidfvectorizer\",\"stemmedcountvectorizer\",\"stemmedtfidfvectorizer\"]\n",
    "vectorizer_params_dict = {}\n",
    "\n",
    "for vect_name in vectorizer_names:\n",
    "    vectorizer_params_dict[vect_name] = {}\n",
    "    for key, value in attributes.items():\n",
    "        param_name = vect_name + \"__\" + key\n",
    "        vectorizer_params_dict[vect_name][param_name] = value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
